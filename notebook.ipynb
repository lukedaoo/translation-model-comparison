{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e91702d-4cdc-4144-b3a8-7764e54351c2",
   "metadata": {},
   "source": [
    "# Compare Translations: mBART vs. Google Translate API\n",
    "Author: Loc Dao (LD) - locdao.fw@gmail.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "958f2498-ebf7-4320-b601-d57e7df8df0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import easyocr\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import json\n",
    "from google.cloud import translate_v2 as translate\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a94c35b-67cb-4ba9-9169-22b8426161b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luked/.conda/envs/tm/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer successfully downloaded and loaded!\n",
      "Input (English): Hello, This is LD. How are you doing today?\n",
      "Translated (French): Bonjour, je suis LD. Comment va-t-il aujourd'hui?\n"
     ]
    }
   ],
   "source": [
    "# Download and check if model works\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "model_name = \"facebook/mbart-large-50-many-to-many-mmt\"\n",
    "local_dir = \"./model/\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast = False, cache_dir=local_dir)\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name, cache_dir=local_dir)\n",
    "\n",
    "print(\"Model and tokenizer successfully downloaded and loaded!\")\n",
    "\n",
    "text = \"Hello, This is LD. How are you doing today?\"\n",
    "source_lang = \"en_XX\"  \n",
    "target_lang = \"fr_XX\"\n",
    "\n",
    "tokenizer.src_lang = source_lang\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "translated_tokens = model.generate(\n",
    "    **inputs,\n",
    "    forced_bos_token_id=tokenizer.lang_code_to_id[target_lang],\n",
    "    max_length=50\n",
    ")\n",
    "\n",
    "translated_text = tokenizer.decode(translated_tokens[0], skip_special_tokens=True)\n",
    "print(\"Input (English):\", text)\n",
    "print(\"Translated (French):\", translated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4a7ac50-bcea-485a-93d4-ce7f98448fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare ocr\n",
    "supported_lang_ch = ['ch_sim', 'en']  \n",
    "supported_lang_others = ['en', 'es', 'de', 'fr']  \n",
    "\n",
    "reader_ch = easyocr.Reader(supported_lang_ch, gpu=True) \n",
    "reader_others = easyocr.Reader(supported_lang_others, gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17f7e09c-cd68-4941-9258-5eb189669b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils func\n",
    "def prepare_ocr_data(dir_path, context):\n",
    "    print(f\"Progressing directory {dir_path}:\") \n",
    "    valid_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff'}\n",
    "    \n",
    "    results = []\n",
    "    ocr_reader = context[\"reader\"]\n",
    "    source_lang = context[\"source_lang\"]\n",
    "           \n",
    "    for filename in os.listdir(dir_path):\n",
    "        file_path = os.path.join(dir_path, filename)\n",
    "        if os.path.isfile(file_path) and os.path.splitext(filename)[1].lower() in valid_extensions:\n",
    "            print(f\"    Progressing {file_path}\") \n",
    "            ocr_result = ocr_reader.readtext(file_path, detail = 0, paragraph=True)\n",
    "            for idx, text in enumerate(ocr_result):\n",
    "                result = {\n",
    "                    \"source_dir\": dir_path,\n",
    "                    \"source_file\": filename,\n",
    "                    \"source_lang\": source_lang,\n",
    "                    \"token_index\": idx,\n",
    "                    \"ocr_original_text\": text\n",
    "                }\n",
    "                results.append(result)\n",
    "        else:\n",
    "            print(f\"    Not a file or does not exist: {filename}\")\n",
    "    return results\n",
    "\n",
    "def make_samples_data():\n",
    "    results = []\n",
    "\n",
    "    results.extend(prepare_ocr_data(\"sample/chi\", {\"source_lang\": \"zh_CN\", \"reader\": reader_ch}))\n",
    "    results.extend(prepare_ocr_data(\"sample/es\", {\"source_lang\": \"es_XX\", \"reader\": reader_others}))\n",
    "    results.extend(prepare_ocr_data(\"sample/ger\", {\"source_lang\": \"de_DE\", \"reader\": reader_others}))\n",
    "    \n",
    "    df = pd.DataFrame(results, columns=[\n",
    "        \"source_dir\", \"source_file\", \"source_lang\",\n",
    "        \"token_index\", \"ocr_original_text\", \n",
    "    ])\n",
    "    return df\n",
    "\n",
    "def load(sample_file):\n",
    "    if os.path.exists(sample_file):\n",
    "        print(f\"Loading sample file...\")\n",
    "        df = pd.read_csv(sample_file)\n",
    "    else:\n",
    "        print(f\"Making sample file...\")\n",
    "        df = make_samples_data()\n",
    "        df.to_csv(sample_file, index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e734b859-9933-4920-a216-a8d7239cf1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading sample file...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_dir</th>\n",
       "      <th>source_file</th>\n",
       "      <th>source_lang</th>\n",
       "      <th>token_index</th>\n",
       "      <th>ocr_original_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sample/chi</td>\n",
       "      <td>foreign-language-immunization-schedules.png</td>\n",
       "      <td>zh_CN</td>\n",
       "      <td>0</td>\n",
       "      <td>IMMUNIZATION RECORD (预防接穆e,) Personal Health A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sample/chi</td>\n",
       "      <td>foreign-language-immunization-schedules.png</td>\n",
       "      <td>zh_CN</td>\n",
       "      <td>1</td>\n",
       "      <td>IMUNIZATION RECORD (嶷  簇</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sample/chi</td>\n",
       "      <td>foreign-language-immunization-schedules.png</td>\n",
       "      <td>zh_CN</td>\n",
       "      <td>2</td>\n",
       "      <td>IIMUNIZATIOV (疫苗)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sample/chi</td>\n",
       "      <td>foreign-language-immunization-schedules.png</td>\n",
       "      <td>zh_CN</td>\n",
       "      <td>3</td>\n",
       "      <td>DOINY 日月年</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sample/chi</td>\n",
       "      <td>foreign-language-immunization-schedules.png</td>\n",
       "      <td>zh_CN</td>\n",
       "      <td>4</td>\n",
       "      <td>DDIIAIY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>sample/ger</td>\n",
       "      <td>3 - ger.jpg</td>\n",
       "      <td>de_DE</td>\n",
       "      <td>0</td>\n",
       "      <td>Weitere Schutzimpfungen Other Vaccinations Imp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>sample/ger</td>\n",
       "      <td>2 - ger.jpg</td>\n",
       "      <td>de_DE</td>\n",
       "      <td>0</td>\n",
       "      <td>MEXIVHAPOIHOE   CBHIETEJIBCTBO 0 BAKLILHALIMI ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>sample/ger</td>\n",
       "      <td>2 - ger.jpg</td>\n",
       "      <td>de_DE</td>\n",
       "      <td>1</td>\n",
       "      <td>KeM I3rO TOBJCHa [ounIc6 IOJUKHOCTb OquunabHas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>sample/ger</td>\n",
       "      <td>2 - ger.jpg</td>\n",
       "      <td>de_DE</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>sample/ger</td>\n",
       "      <td>1 - ger.jpg</td>\n",
       "      <td>de_DE</td>\n",
       "      <td>0</td>\n",
       "      <td>Other vaccinations Autres vaccinations Weitere...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     source_dir                                  source_file source_lang  \\\n",
       "0    sample/chi  foreign-language-immunization-schedules.png       zh_CN   \n",
       "1    sample/chi  foreign-language-immunization-schedules.png       zh_CN   \n",
       "2    sample/chi  foreign-language-immunization-schedules.png       zh_CN   \n",
       "3    sample/chi  foreign-language-immunization-schedules.png       zh_CN   \n",
       "4    sample/chi  foreign-language-immunization-schedules.png       zh_CN   \n",
       "..          ...                                          ...         ...   \n",
       "170  sample/ger                                  3 - ger.jpg       de_DE   \n",
       "171  sample/ger                                  2 - ger.jpg       de_DE   \n",
       "172  sample/ger                                  2 - ger.jpg       de_DE   \n",
       "173  sample/ger                                  2 - ger.jpg       de_DE   \n",
       "174  sample/ger                                  1 - ger.jpg       de_DE   \n",
       "\n",
       "     token_index                                  ocr_original_text  \n",
       "0              0  IMMUNIZATION RECORD (预防接穆e,) Personal Health A...  \n",
       "1              1                           IMUNIZATION RECORD (嶷  簇  \n",
       "2              2                                  IIMUNIZATIOV (疫苗)  \n",
       "3              3                                          DOINY 日月年  \n",
       "4              4                                            DDIIAIY  \n",
       "..           ...                                                ...  \n",
       "170            0  Weitere Schutzimpfungen Other Vaccinations Imp...  \n",
       "171            0  MEXIVHAPOIHOE   CBHIETEJIBCTBO 0 BAKLILHALIMI ...  \n",
       "172            1  KeM I3rO TOBJCHa [ounIc6 IOJUKHOCTb OquunabHas...  \n",
       "173            2                                                  2  \n",
       "174            0  Other vaccinations Autres vaccinations Weitere...  \n",
       "\n",
       "[175 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load or make sample_file\n",
    "# print(prepare_ocr_data(\"sample/chi\", {\"source_lang\": \"chi_sim\", \"target_lang\": \"en_US\", \"reader\": reader_ch}))\n",
    "# print(prepare_ocr_data(\"sample/es\", {\"source_lang\": \"es\", \"target_lang\": \"en_US\", \"reader\": reader_others}))\n",
    "# print(prepare_ocr_data(\"sample/ger\", {\"source_lang\": \"ger\", \"target_lang\": \"en_US\", \"reader\": reader_others}))\n",
    "\n",
    "sample_file = \"ocr_results.csv\"\n",
    "\n",
    "df = load(sample_file)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6aff6b2c-4ed4-4b53-a113-6529b4c92609",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model supported lang\n",
    "# ['ar_AR', 'cs_CZ', 'de_DE', 'en_XX', 'es_XX', \n",
    "#  'et_EE', 'fi_FI', 'fr_XX', 'gu_IN', \n",
    "#  'hi_IN', 'it_IT', 'ja_XX', 'kk_KZ', \n",
    "#  'ko_KR', 'lt_LT', 'lv_LV', 'my_MM', \n",
    "#  'ne_NP', 'nl_XX', 'ro_RO', 'ru_RU', 'si_LK', 'tr_TR', \n",
    "#  'vi_VN', 'zh_CN', 'af_ZA', 'az_AZ', \n",
    "#  'bn_IN', 'fa_IR', 'he_IL', 'hr_HR', \n",
    "#  'id_ID', 'ka_GE', 'km_KH', 'mk_MK', \n",
    "#  'ml_IN', 'mn_MN', 'mr_IN', 'pl_PL', \n",
    "#  'ps_AF', 'pt_XX', 'sv_SE', 'sw_KE', \n",
    "#  'ta_IN', 'te_IN', 'th_TH', 'tl_XX', \n",
    "#  'uk_UA', 'ur_PK', 'xh_ZA', 'gl_ES', 'sl_SI']\n",
    "def translate_with_facebook_model(text, source_lang, target_lang):\n",
    "    tokenizer.src_lang = source_lang\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    \n",
    "    translated_tokens = model.generate(\n",
    "        **inputs,\n",
    "        forced_bos_token_id=tokenizer.lang_code_to_id[target_lang],\n",
    "        max_length=300\n",
    "    )\n",
    "    translated_text = tokenizer.decode(translated_tokens[0], skip_special_tokens=True)\n",
    "    return translated_text\n",
    "\n",
    "def translate_row(row, target_lang=\"en_XX\"):\n",
    "    source_lang = row[\"source_lang\"]\n",
    "    text = row[\"ocr_original_text\"]\n",
    "    translated = translate_with_facebook_model(str(text), source_lang, target_lang)\n",
    "    return row.name, translated\n",
    "\n",
    "def do_facebook(): \n",
    "    max_workers = min(4, os.cpu_count() or 1)\n",
    "    total_rows = len(df)\n",
    "    print(f\"Starting translation for {total_rows} rows with {max_workers} threads...\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        future_to_index = {executor.submit(translate_row, row): row.name for index, row in df.iterrows()}\n",
    "        with tqdm(total=total_rows, desc=\"Translating\", unit=\"row\") as pbar:\n",
    "            completed = 0\n",
    "            failed = 0\n",
    "            for future in as_completed(future_to_index):\n",
    "                try:\n",
    "                    index, translated = future.result()\n",
    "                    df.at[index, \"translated_by_mbart\"] = translated\n",
    "                    completed += 1\n",
    "                    pbar.update(1)\n",
    "                except Exception as e:\n",
    "                    print(f\"Future failed for index {future_to_index[future]}: {e}\")\n",
    "                    failed += 1\n",
    "                    pbar.update(1)\n",
    "                \n",
    "                # Periodic status update\n",
    "                if completed % 10 == 0 or completed + failed == total_rows:\n",
    "                    elapsed = time.time() - start_time\n",
    "                    remaining = (elapsed / completed * (total_rows - completed - failed)) if completed > 0 else 0\n",
    "                    print(f\"Status: {completed} completed, {failed} failed, {total_rows - completed - failed} pending, \"\n",
    "                          f\"Elapsed: {elapsed:.1f}s, ETA: {remaining:.1f}s\")\n",
    "    \n",
    "    df.to_csv(\"translated_with_facebook_model.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a26c28d9-f4f8-4ac7-86ed-13fd633ae9fe",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting translation for 175 rows with 4 threads...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating:   7%|█▋                      | 12/175 [00:00<00:05, 28.87row/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: 10 completed, 0 failed, 165 pending, Elapsed: 0.6s, ETA: 10.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating:  15%|███▌                    | 26/175 [00:00<00:04, 34.96row/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: 20 completed, 0 failed, 155 pending, Elapsed: 0.9s, ETA: 7.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating:  19%|████▋                   | 34/175 [00:01<00:04, 31.18row/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: 30 completed, 0 failed, 145 pending, Elapsed: 1.2s, ETA: 5.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating:  27%|██████▍                 | 47/175 [00:01<00:02, 47.32row/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: 40 completed, 0 failed, 135 pending, Elapsed: 1.5s, ETA: 4.9s\n",
      "Status: 50 completed, 0 failed, 125 pending, Elapsed: 1.6s, ETA: 4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating:  39%|█████████▎              | 68/175 [00:01<00:01, 53.75row/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: 60 completed, 0 failed, 115 pending, Elapsed: 1.8s, ETA: 3.4s\n",
      "Status: 70 completed, 0 failed, 105 pending, Elapsed: 1.9s, ETA: 2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating:  50%|████████████            | 88/175 [00:02<00:01, 54.02row/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: 80 completed, 0 failed, 95 pending, Elapsed: 2.2s, ETA: 2.6s\n",
      "Status: 90 completed, 0 failed, 85 pending, Elapsed: 2.3s, ETA: 2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating:  61%|█████████████▉         | 106/175 [00:02<00:01, 54.47row/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: 100 completed, 0 failed, 75 pending, Elapsed: 2.5s, ETA: 1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating:  67%|███████████████▌       | 118/175 [00:02<00:01, 48.88row/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: 110 completed, 0 failed, 65 pending, Elapsed: 2.7s, ETA: 1.6s\n",
      "Status: 120 completed, 0 failed, 55 pending, Elapsed: 2.9s, ETA: 1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating:  78%|██████████████████     | 137/175 [00:03<00:00, 51.62row/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: 130 completed, 0 failed, 45 pending, Elapsed: 3.1s, ETA: 1.1s\n",
      "Status: 140 completed, 0 failed, 35 pending, Elapsed: 3.3s, ETA: 0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating:  89%|████████████████████▎  | 155/175 [00:03<00:00, 52.28row/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: 150 completed, 0 failed, 25 pending, Elapsed: 3.5s, ETA: 0.6s\n",
      "Status: 160 completed, 0 failed, 15 pending, Elapsed: 3.7s, ETA: 0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating:  98%|██████████████████████▌| 172/175 [00:03<00:00, 42.58row/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: 170 completed, 0 failed, 5 pending, Elapsed: 3.9s, ETA: 0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating: 100%|███████████████████████| 175/175 [00:03<00:00, 44.21row/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: 175 completed, 0 failed, 0 pending, Elapsed: 4.1s, ETA: 0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "config_path = \"./config.json\"\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = config_path\n",
    "google_client = translate.Client()\n",
    "\n",
    "def translate_with_google(text, source_lang, target_lang):\n",
    "    return google_client.translate(text,source_language=source_lang,target_language=target_lang)\n",
    "    \n",
    "def translate_row_(row, target_lang=\"en\"):\n",
    "    lang_map = {\n",
    "        \"chi_sim\": \"zh-CN\",\n",
    "        \"es_XX\": \"es\",\n",
    "        \"de_DE\": \"de\",\n",
    "        \"en_XX\": \"en\"\n",
    "    }\n",
    "    source_lang = lang_map.get(row[\"source_lang\"], row[\"source_lang\"])\n",
    "    text = row[\"ocr_original_text\"]\n",
    "    translated = translate_with_google(str(text), source_lang, target_lang)\n",
    "    return row.name, translated[\"translatedText\"]\n",
    "    \n",
    "def do_google():\n",
    "    max_workers = min(4, os.cpu_count() or 1)\n",
    "    total_rows = len(df)\n",
    "    print(f\"Starting translation for {total_rows} rows with {max_workers} threads...\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        future_to_index = {executor.submit(translate_row_, row): row.name for index, row in df.iterrows()}\n",
    "        with tqdm(total=total_rows, desc=\"Translating\", unit=\"row\") as pbar:\n",
    "            completed = 0\n",
    "            failed = 0\n",
    "            for future in as_completed(future_to_index):\n",
    "                try:\n",
    "                    index, translated = future.result()\n",
    "                    df.at[index, \"translated_by_google\"] = translated\n",
    "                    completed += 1\n",
    "                    pbar.update(1)\n",
    "                except Exception as e:\n",
    "                    print(f\"Future failed for index {future_to_index[future]}: {e}\")\n",
    "                    failed += 1\n",
    "                    pbar.update(1)\n",
    "                \n",
    "                # Periodic status update\n",
    "                if completed % 10 == 0 or completed + failed == total_rows:\n",
    "                    elapsed = time.time() - start_time\n",
    "                    remaining = (elapsed / completed * (total_rows - completed - failed)) if completed > 0 else 0\n",
    "                    print(f\"Status: {completed} completed, {failed} failed, {total_rows - completed - failed} pending, \"\n",
    "                          f\"Elapsed: {elapsed:.1f}s, ETA: {remaining:.1f}s\")\n",
    "    df.to_csv(\"translated_with_google.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "46839a27-0c2e-4a2c-be45-adfa6bae663e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FB] Original text: DATE GIVEN focha de vacunación\n",
      "[FB] translated: The Committee recommends that the State party take all necessary measures to ensure the full enjoyment of all human rights and fundamental freedoms, including the right to education, including the right to health, the right to food, the right\n",
      "[GG] Original text: DATE GIVEN focha de vacunación\n",
      "[GG] translated: {'translatedText': 'DATE GIVEN vaccination token', 'input': 'DATE GIVEN focha de vacunación'}\n"
     ]
    }
   ],
   "source": [
    "df_facebook = pd.read_csv(\"translated_with_facebook_model.csv\")\n",
    "text = df_facebook.at[158 - 1, \"ocr_original_text\"]\n",
    "src_lang = df_facebook.at[158 - 1, \"source_lang\"]\n",
    "target_lang = \"en_XX\"\n",
    "print(f\"[FB] Original text: {text}\")\n",
    "print(f\"[FB] translated: {translate_with_facebook_model(text, src_lang, target_lang)}\")\n",
    "\n",
    "df_google = pd.read_csv(\"translated_with_google.csv\")\n",
    "text = df_google.at[158 - 1, \"ocr_original_text\"]\n",
    "src_lang = \"es\" if df_google.at[158 - 1, \"source_lang\"] == \"es_XX\" else \"es_XX\"\n",
    "target_lang = \"en\"\n",
    "print(f\"[GG] Original text: {text}\")\n",
    "print(f\"[GG] translated: {translate_with_google(text, src_lang, target_lang)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91af2c4a-74f7-4edf-92e0-35ec14d9824b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
